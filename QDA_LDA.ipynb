{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, power_transform, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('0_X_train.csv', index_col='Id')\n",
    "X_valid = pd.read_csv('1_X_valid.csv', index_col='Id')\n",
    "X_test  = pd.read_csv('2_X_test.csv', index_col='Id')\n",
    "\n",
    "y_train = pd.read_csv('0_y_train.csv', index_col='Id')\n",
    "y_valid = pd.read_csv('1_y_valid.csv', index_col='Id')\n",
    "y_test  = pd.read_csv('2_y_test.csv', index_col='Id')\n",
    "\n",
    "num_vars = ['age', 'time_spent', 'banner_views', 'banner_views_old', 'days_elapsed_old', 'X4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [\n",
    "    ('power_transform', PowerTransformer(standardize = True), num_vars)  # Power transformation and Standardization\n",
    "]\n",
    "\n",
    "std_num = ColumnTransformer(transformers=transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LDA = Pipeline([\n",
    "    ('std_num', std_num),\n",
    "    (\"lda\", LinearDiscriminantAnalysis())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA --- Accuracy on training data: 0.819\n",
      "LDA --- Accuracy on valid data: 0.798\n",
      "LDA --- Accuracy on test data: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit pipeline\n",
    "pipe_LDA.fit(X_train, y_train) # Fit it to the training data \n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = pipe_LDA.predict(X_train) # Predict the class labels for the training data\n",
    "acc = accuracy_score(y_train, y_train_pred) # Calculate the accuracy of the predictions \n",
    "print(\"LDA --- Accuracy on training data:\", np.round(acc, 3))\n",
    "\n",
    "# Predict on valid data\n",
    "y_valid_pred = pipe_LDA.predict(X_valid) # Predict the class labels for the valid data\n",
    "acc = accuracy_score(y_valid, y_valid_pred) # Calculate the accuracy of the predictions \n",
    "print(\"LDA --- Accuracy on valid data:\", np.round(acc, 3))\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = pipe_LDA.predict(X_test) # Predict the class labels for the test data\n",
    "acc = accuracy_score(y_test, y_test_pred) # Calculate the accuracy of the predictions \n",
    "print(\"LDA --- Accuracy on test data:\", np.round(acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.816 (0.012)\n"
     ]
    }
   ],
   "source": [
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(pipe_LDA, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Summarize result\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# https://machinelearningmastery.com/linear-discriminant-analysis-with-python/\n",
    "# Running the example evaluates the Linear Discriminant Analysis algorithm on the synthetic dataset and reports the average accuracy across the three repeats of 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 9 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "84 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 599, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 440, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 16 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 599, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 440, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 20 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 599, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 440, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 31 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.79896986 0.79896986 0.79896986 0.79896986 0.79896986 0.79896986\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7989698566291807"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune LDA Hyperparameters\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_param_grid = {\"solver\" : ['svd', 'lsqr', 'eigen'],\n",
    "              \"tol\" : [0.0001,0.0002,0.0003]}\n",
    "\n",
    "gsLDA = GridSearchCV(LDA, param_grid = lda_param_grid, cv=cv,\n",
    "                     scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsLDA.fit(X_train,y_train)\n",
    "LDA_best = gsLDA.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsLDA.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "pipe_QDA = Pipeline(\n",
    "    [(\"power\", PowerTransformer()), \n",
    "     (\"qda\", QuadraticDiscriminantAnalysis())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('power', PowerTransformer()),\n",
       "                ('qda', QuadraticDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit pipeline\n",
    "pipe_QDA.fit(X_train, y_train) # Fit it to the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('power', PowerTransformer()),\n",
       "                ('qda', QuadraticDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add noise before fitting again\n",
    "def add_noise(X, scale):\n",
    "    \"\"\"\n",
    "    DataFrame double -> ndarray\n",
    "    produce DataFrame adding Gaussian with standard deviation = `scale` to each column of `X`.\n",
    "    \"\"\"\n",
    "    # Transform to ndarray\n",
    "    X_arr = X.to_numpy()\n",
    "\n",
    "    # Get shape\n",
    "    n, d = X_arr.shape\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    X_arr = X_arr + np.random.normal(scale = scale, size = (n, d))\n",
    "\n",
    "    # Back to DataFrame\n",
    "    df = pd.DataFrame(X_arr, columns = [\"X\" + str(i) for i in range(1, d + 1)])\n",
    "\n",
    "    # Return df\n",
    "    return df\n",
    "\n",
    "X_train_noise = add_noise(X_train, scale = 0.1) # Add random noise to the input and controls the amount of the noise added\n",
    "pipe_QDA.fit(X_train_noise, y_train) # Fit it to the training data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datasklr.com/select-classification-methods/linear-and-quadratic-discriminant-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>device</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>banner_views</th>\n",
       "      <th>banner_views_old</th>\n",
       "      <th>days_elapsed_old</th>\n",
       "      <th>X1</th>\n",
       "      <th>...</th>\n",
       "      <th>job_student^2</th>\n",
       "      <th>job_student job_teacher</th>\n",
       "      <th>job_student job_technology</th>\n",
       "      <th>job_student job_unemployed</th>\n",
       "      <th>job_teacher^2</th>\n",
       "      <th>job_teacher job_technology</th>\n",
       "      <th>job_teacher job_unemployed</th>\n",
       "      <th>job_technology^2</th>\n",
       "      <th>job_technology job_unemployed</th>\n",
       "      <th>job_unemployed^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  education  device   day  month  time_spent  banner_views  \\\n",
       "0  39.0        2.0     0.0   9.0    2.0        5.75           2.0   \n",
       "1  38.0        2.0     0.0  14.0    5.0       14.20           2.0   \n",
       "2  36.0        2.0     0.0  12.0    2.0       20.45           2.0   \n",
       "3  25.0        0.0     0.0   7.0    7.0        5.30           1.0   \n",
       "4  30.0        2.0     0.0   4.0    6.0        9.20           1.0   \n",
       "\n",
       "   banner_views_old  days_elapsed_old   X1  ...  job_student^2  \\\n",
       "0               2.0             183.0  0.0  ...            0.0   \n",
       "1               0.0              -1.0  0.0  ...            0.0   \n",
       "2               1.0             183.0  0.0  ...            0.0   \n",
       "3               0.0              -1.0  0.0  ...            0.0   \n",
       "4               0.0              -1.0  0.0  ...            0.0   \n",
       "\n",
       "   job_student job_teacher  job_student job_technology  \\\n",
       "0                      0.0                         0.0   \n",
       "1                      0.0                         0.0   \n",
       "2                      0.0                         0.0   \n",
       "3                      0.0                         0.0   \n",
       "4                      0.0                         0.0   \n",
       "\n",
       "   job_student job_unemployed  job_teacher^2  job_teacher job_technology  \\\n",
       "0                         0.0            0.0                         0.0   \n",
       "1                         0.0            0.0                         0.0   \n",
       "2                         0.0            0.0                         0.0   \n",
       "3                         0.0            0.0                         0.0   \n",
       "4                         0.0            0.0                         0.0   \n",
       "\n",
       "   job_teacher job_unemployed  job_technology^2  \\\n",
       "0                         0.0               0.0   \n",
       "1                         0.0               1.0   \n",
       "2                         0.0               1.0   \n",
       "3                         0.0               0.0   \n",
       "4                         0.0               0.0   \n",
       "\n",
       "   job_technology job_unemployed  job_unemployed^2  \n",
       "0                            0.0               0.0  \n",
       "1                            0.0               0.0  \n",
       "2                            0.0               0.0  \n",
       "3                            0.0               0.0  \n",
       "4                            0.0               0.0  \n",
       "\n",
       "[5 rows x 527 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create interaction terms (interaction of each regressor pair + polynomial)\n",
    "#Interaction terms need to be created in both the test and train datasets\n",
    "interaction2 = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False, order='C') #second degree\n",
    "interaction3 = PolynomialFeatures(degree=3, include_bias=False, interaction_only=False, order='C') #third degree\n",
    "\n",
    "# Training\n",
    "X_train_2 = pd.DataFrame(interaction2.fit_transform(X_train), columns=interaction2.get_feature_names(input_features=X_train.columns))\n",
    "X_train_3 = pd.DataFrame(interaction3.fit_transform(X_train), columns=interaction3.get_feature_names(input_features=X_train.columns))\n",
    "X_train_2.head()\n",
    "\n",
    "# Validation\n",
    "X_valid_2 = pd.DataFrame(interaction2.fit_transform(X_valid), columns=interaction2.get_feature_names(input_features=X_valid.columns))\n",
    "X_valid_3 = pd.DataFrame(interaction3.fit_transform(X_valid), columns=interaction3.get_feature_names(input_features=X_valid.columns))\n",
    "X_valid_2.head()\n",
    "\n",
    "# Test\n",
    "X_test_2 = pd.DataFrame(interaction2.fit_transform(X_test), columns=interaction2.get_feature_names(input_features=X_test.columns))\n",
    "X_test_3 = pd.DataFrame(interaction3.fit_transform(X_test), columns=interaction3.get_feature_names(input_features=X_test.columns))\n",
    "X_test_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Normalize all datasets \n",
    "#############################\n",
    "\n",
    "power = PowerTransformer()\n",
    "\n",
    "\n",
    "# Standardize the training sets: 1st, 2nd and 3rd order polynomials\n",
    "X_train=pd.DataFrame(power.fit_transform(X_train), columns=X_train.columns)\n",
    "X_train_2=pd.DataFrame(power.fit_transform(X_train_2), columns=X_train_2.columns)\n",
    "X_train_3=pd.DataFrame(power.fit_transform(X_train_3), columns=X_train_3.columns)\n",
    "\n",
    "# Standardize the validation sets: 1st, 2nd and 3rd order polynomials\n",
    "X_valid=pd.DataFrame(power.fit_transform(X_valid), columns=X_valid.columns)\n",
    "X_valid_2=pd.DataFrame(power.fit_transform(X_valid_2), columns=X_valid_2.columns)\n",
    "X_valid_3=pd.DataFrame(power.fit_transform(X_valid_3), columns=X_valid_3.columns)\n",
    "\n",
    "# Standardize the test sets: 1st, 2nd and 3rd order polynomials\n",
    "X_test=pd.DataFrame(power.fit_transform(X_test), columns=X_test.columns)\n",
    "X_test_2=pd.DataFrame(power.fit_transform(X_test_2), columns=X_test_2.columns)\n",
    "X_test_3=pd.DataFrame(power.fit_transform(X_test_3), columns=X_test_3.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    VIF Factor               features\n",
      "0          1.0                  const\n",
      "1          1.9                    age\n",
      "2          1.8              education\n",
      "3          1.1                 device\n",
      "4          1.0                    day\n",
      "5          1.1                  month\n",
      "6          1.0             time_spent\n",
      "7          1.1           banner_views\n",
      "8        205.4       banner_views_old\n",
      "9        561.8       days_elapsed_old\n",
      "10         1.0                     X1\n",
      "11         1.0                     X2\n",
      "12         1.2                     X3\n",
      "13         1.1                     X4\n",
      "14         inf       marital_divorced\n",
      "15         inf        marital_married\n",
      "16         inf         marital_single\n",
      "17         inf    outcome_old_failure\n",
      "18         inf         outcome_old_na\n",
      "19         inf      outcome_old_other\n",
      "20         inf    outcome_old_success\n",
      "21         inf       job_entrepreneur\n",
      "22         inf          job_freelance\n",
      "23         inf        job_housekeeper\n",
      "24         inf  job_industrial_worker\n",
      "25         inf            job_manager\n",
      "26         inf            job_retired\n",
      "27         inf           job_salesman\n",
      "28         inf            job_student\n",
      "29         inf            job_teacher\n",
      "30         inf         job_technology\n",
      "31         inf         job_unemployed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Deal with multicollinearity\n",
    "################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#1st order polynomial ######################\n",
    "x_temp_train1 = sm.add_constant(X_train)\n",
    "vif_train1 = pd.DataFrame()\n",
    "vif_train1[\"VIF Factor\"] = [variance_inflation_factor(x_temp_train1.values, i) for i in range(x_temp_train1.values.shape[1])]\n",
    "vif_train1[\"features\"] = x_temp_train1.columns\n",
    "pd.set_option('display.max_rows', 300)\n",
    "print(vif_train1.round(1))\n",
    "\n",
    "\n",
    "# Identify all variables wit VIF less then 5 and keep\n",
    "vif_train1_a=vif_train1[vif_train1[\"VIF Factor\"]<5.0]  # print(vif2.round(1))\n",
    "\n",
    "feat_list=vif_train1_a[\"features\"].tolist()  #save desired features to list\n",
    "feat_list.remove(feat_list[0])\n",
    "print(feat_list)\n",
    "\n",
    "X_train=X_train[feat_list] #keep features on feature list only, drop all other features for train\n",
    "X_valid=X_valid[feat_list] #keep features on feature list only, drop all other features for valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1736: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['device X2', 'device X3', 'X1 X2', 'X1 X3', 'X2 X3']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device X2</th>\n",
       "      <th>device X3</th>\n",
       "      <th>X1 X2</th>\n",
       "      <th>X1 X3</th>\n",
       "      <th>X2 X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>3.753650</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>3.753650</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126036</td>\n",
       "      <td>-0.054656</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.082138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1343 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      device X2  device X3     X1 X2     X1 X3     X2 X3\n",
       "0           0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "1           0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "2           0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "3           0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "4           0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "...         ...        ...       ...       ...       ...\n",
       "1338        0.0  -0.126036 -0.054656  3.753650 -0.082138\n",
       "1339        0.0  -0.126036 -0.054656  3.753650 -0.082138\n",
       "1340        0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "1341        0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "1342        0.0  -0.126036 -0.054656 -0.266407 -0.082138\n",
       "\n",
       "[1343 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2nd order polynomial ####################\n",
    "x_temp_train2 = sm.add_constant(X_train_2)\n",
    "vif_train2 = pd.DataFrame()\n",
    "vif_train2[\"VIF Factor\"] = [variance_inflation_factor(x_temp_train2.values, i) for i in range(x_temp_train2.values.shape[1])]\n",
    "vif_train2[\"features\"] = x_temp_train2.columns\n",
    "pd.set_option('display.max_rows', 300)\n",
    "#print(vif_train1.round(1))\n",
    "\n",
    "vif_train2_a=vif_train2[vif_train2[\"VIF Factor\"]<5.0]\n",
    "#print(vif2.round(1))\n",
    "\n",
    "feat_list2=vif_train2_a[\"features\"].tolist()\n",
    "feat_list2.remove(feat_list2[0])\n",
    "print(feat_list2)\n",
    "\n",
    "X_train_2=X_train_2[feat_list2] #keep features on feature list only, drop all other features for train\n",
    "X_valid_2=X_valid_2[feat_list2] #keep features on feature list only, drop all other features for valid\n",
    "X_valid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11052\\1532773381.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_temp_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvif_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mvif_train3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"VIF Factor\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_temp_train3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_temp_train3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvif_train3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_temp_train3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11052\\1532773381.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_temp_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvif_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mvif_train3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"VIF Factor\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_temp_train3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_temp_train3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvif_train3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_temp_train3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\emann\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py\u001b[0m in \u001b[0;36mvariance_inflation_factor\u001b[1;34m(exog, exog_idx)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_vars\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexog_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mx_noti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[0mr_squared_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_noti\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsquared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m     \u001b[0mvif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr_squared_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvif\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\emann\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m                     hasattr(self, 'rank')):\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv_wexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingular_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpinv_extended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m                 self.normalized_cov_params = np.dot(\n\u001b[0;32m    308\u001b[0m                     self.pinv_wexog, np.transpose(self.pinv_wexog))\n",
      "\u001b[1;32mc:\\Users\\emann\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\tools.py\u001b[0m in \u001b[0;36mpinv_extended\u001b[1;34m(x, rcond)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m     \u001b[0ms_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\emann\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\emann\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m         \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DdD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->ddd'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m         \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1658\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#3rd order polynomial ####################\n",
    "x_temp_train3 = sm.add_constant(X_train_3)\n",
    "vif_train3 = pd.DataFrame()\n",
    "vif_train3[\"VIF Factor\"] = [variance_inflation_factor(x_temp_train3.values, i) for i in range(x_temp_train3.values.shape[1])]\n",
    "vif_train3[\"features\"] = x_temp_train3.columns\n",
    "pd.set_option('display.max_rows', 300)\n",
    "#print(vif_train3.round(1))\n",
    "\n",
    "vif_train3_a=vif_train3[vif_train3[\"VIF Factor\"]<5.0]\n",
    "#print(vif3.round(1))\n",
    "\n",
    "feat_list3=vif_train3_a[\"features\"].tolist()\n",
    "feat_list3.remove(feat_list3[0])\n",
    "print(feat_list3)\n",
    "\n",
    "X_train_3=X_train_3[feat_list3] #keep features on feature list only, drop all other features for train\n",
    "X_valid_3=X_valid_3[feat_list3]   #keep features on feature list only, drop all other features for valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default LDA model without any tuning - base metric\n",
    "LDA_model_default = LinearDiscriminantAnalysis()\n",
    "LDA_model_default.fit(X_train, y_train)\n",
    "y_pred_LDA_default =LDA_model_default.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
