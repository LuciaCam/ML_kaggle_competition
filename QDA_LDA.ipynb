{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, power_transform, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('0_X_train.csv', index_col='Id')\n",
    "X_valid = pd.read_csv('1_X_valid.csv', index_col='Id')\n",
    "X_test  = pd.read_csv('2_X_test.csv', index_col='Id')\n",
    "\n",
    "y_train = pd.read_csv('0_y_train.csv', index_col='Id')\n",
    "y_valid = pd.read_csv('1_y_valid.csv', index_col='Id')\n",
    "y_test  = pd.read_csv('2_y_test.csv', index_col='Id')\n",
    "\n",
    "num_vars = ['age', 'time_spent', 'banner_views', 'banner_views_old', 'days_elapsed_old', 'X4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [\n",
    "    ('power_transform', PowerTransformer(standardize = True), num_vars)  # Power transformation and Standardization\n",
    "]\n",
    "\n",
    "std_num = ColumnTransformer(transformers=transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LDA = Pipeline([\n",
    "    ('std_num', std_num),\n",
    "    (\"lda\", LinearDiscriminantAnalysis())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA --- Accuracy on training data: 0.819\n",
      "LDA --- Accuracy on valid data: 0.798\n",
      "LDA --- Accuracy on test data: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit pipeline\n",
    "pipe_LDA.fit(X_train, y_train) # Fit it to the training data \n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = pipe_LDA.predict(X_train) # Predict the class labels for the training data\n",
    "acc = accuracy_score(y_train, y_train_pred) # Calculate the accuracy of the predictions \n",
    "print(\"LDA --- Accuracy on training data:\", np.round(acc, 3))\n",
    "\n",
    "# Predict on valid data\n",
    "y_valid_pred = pipe_LDA.predict(X_valid) # Predict the class labels for the valid data\n",
    "acc = accuracy_score(y_valid, y_valid_pred) # Calculate the accuracy of the predictions \n",
    "print(\"LDA --- Accuracy on valid data:\", np.round(acc, 3))\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = pipe_LDA.predict(X_test) # Predict the class labels for the test data\n",
    "acc = accuracy_score(y_test, y_test_pred) # Calculate the accuracy of the predictions \n",
    "print(\"LDA --- Accuracy on test data:\", np.round(acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.816 (0.012)\n"
     ]
    }
   ],
   "source": [
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(pipe_LDA, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Summarize result\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# https://machinelearningmastery.com/linear-discriminant-analysis-with-python/\n",
    "# Running the example evaluates the Linear Discriminant Analysis algorithm on the synthetic dataset and reports the average accuracy across the three repeats of 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 9 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "84 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 599, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 440, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 16 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 599, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 440, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 20 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 599, in fit\n",
      "    self._solve_eigen(\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 440, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"c:\\Users\\emann\\anaconda3\\lib\\site-packages\\scipy\\linalg\\_decomp.py\", line 594, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 31 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.79896986 0.79896986 0.79896986 0.79896986 0.79896986 0.79896986\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7989698566291807"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune LDA Hyperparameters\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda_param_grid = {\"solver\" : ['svd', 'lsqr', 'eigen'],\n",
    "              \"tol\" : [0.0001,0.0002,0.0003]}\n",
    "\n",
    "gsLDA = GridSearchCV(LDA, param_grid = lda_param_grid, cv=cv,\n",
    "                     scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsLDA.fit(X_train,y_train)\n",
    "LDA_best = gsLDA.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsLDA.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "pipe_QDA = Pipeline(\n",
    "    [(\"power\", PowerTransformer()), \n",
    "     (\"qda\", QuadraticDiscriminantAnalysis())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('power', PowerTransformer()),\n",
       "                ('qda', QuadraticDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit pipeline\n",
    "pipe_QDA.fit(X_train, y_train) # Fit it to the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('power', PowerTransformer()),\n",
       "                ('qda', QuadraticDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add noise before fitting again\n",
    "def add_noise(X, scale):\n",
    "    \"\"\"\n",
    "    DataFrame double -> ndarray\n",
    "    produce DataFrame adding Gaussian with standard deviation = `scale` to each column of `X`.\n",
    "    \"\"\"\n",
    "    # Transform to ndarray\n",
    "    X_arr = X.to_numpy()\n",
    "\n",
    "    # Get shape\n",
    "    n, d = X_arr.shape\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    X_arr = X_arr + np.random.normal(scale = scale, size = (n, d))\n",
    "\n",
    "    # Back to DataFrame\n",
    "    df = pd.DataFrame(X_arr, columns = [\"X\" + str(i) for i in range(1, d + 1)])\n",
    "\n",
    "    # Return df\n",
    "    return df\n",
    "\n",
    "X_train_noise = add_noise(X_train, scale = 0.1) # Add random noise to the input and controls the amount of the noise added\n",
    "pipe_QDA.fit(X_train_noise, y_train) # Fit it to the training data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datasklr.com/select-classification-methods/linear-and-quadratic-discriminant-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>device</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>banner_views</th>\n",
       "      <th>banner_views_old</th>\n",
       "      <th>days_elapsed_old</th>\n",
       "      <th>X1</th>\n",
       "      <th>...</th>\n",
       "      <th>job_freelance</th>\n",
       "      <th>job_housekeeper</th>\n",
       "      <th>job_industrial_worker</th>\n",
       "      <th>job_manager</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_salesman</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_teacher</th>\n",
       "      <th>job_technology</th>\n",
       "      <th>job_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.405573</td>\n",
       "      <td>-1.759765</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>-1.154049</td>\n",
       "      <td>0.726880</td>\n",
       "      <td>-1.068475</td>\n",
       "      <td>0.335738</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>-0.409805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>6.006407</td>\n",
       "      <td>-0.485944</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.845879</td>\n",
       "      <td>1.258243</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>-1.293811</td>\n",
       "      <td>0.726880</td>\n",
       "      <td>0.916961</td>\n",
       "      <td>-1.081376</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>-0.409805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>-0.485944</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>2.282566</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.397833</td>\n",
       "      <td>1.258243</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>0.194014</td>\n",
       "      <td>-0.042649</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>-1.081376</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>-0.409805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>6.006407</td>\n",
       "      <td>-0.485944</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.907460</td>\n",
       "      <td>-0.318701</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>1.210360</td>\n",
       "      <td>-0.446910</td>\n",
       "      <td>-0.326755</td>\n",
       "      <td>1.352297</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>-0.409805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>2.057852</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.776010</td>\n",
       "      <td>-0.318701</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>-1.293811</td>\n",
       "      <td>-0.042649</td>\n",
       "      <td>-2.338993</td>\n",
       "      <td>0.882775</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>-0.409805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>-0.485944</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>2.714005</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>0.231171</td>\n",
       "      <td>-1.759765</td>\n",
       "      <td>3.652215</td>\n",
       "      <td>-0.393528</td>\n",
       "      <td>-0.446910</td>\n",
       "      <td>-2.178299</td>\n",
       "      <td>-1.081376</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>-0.409805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>2.057852</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6262</th>\n",
       "      <td>-0.038550</td>\n",
       "      <td>-1.759765</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>-0.274347</td>\n",
       "      <td>-0.446910</td>\n",
       "      <td>2.473490</td>\n",
       "      <td>1.352297</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>2.440183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>2.057852</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>0.555253</td>\n",
       "      <td>-1.759765</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>0.309596</td>\n",
       "      <td>-0.042649</td>\n",
       "      <td>-0.639832</td>\n",
       "      <td>0.882775</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>-0.409805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>2.057852</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>1.461172</td>\n",
       "      <td>-0.318701</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>0.309596</td>\n",
       "      <td>0.726880</td>\n",
       "      <td>-0.963067</td>\n",
       "      <td>1.560307</td>\n",
       "      <td>-0.565174</td>\n",
       "      <td>-0.565178</td>\n",
       "      <td>2.440183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>-0.485944</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>3.697901</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>-0.438103</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>-0.907460</td>\n",
       "      <td>-0.318701</td>\n",
       "      <td>-0.273806</td>\n",
       "      <td>0.538792</td>\n",
       "      <td>1.809339</td>\n",
       "      <td>-0.839007</td>\n",
       "      <td>0.335738</td>\n",
       "      <td>1.780564</td>\n",
       "      <td>1.768878</td>\n",
       "      <td>2.440183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198702</td>\n",
       "      <td>-0.166489</td>\n",
       "      <td>-0.485944</td>\n",
       "      <td>-0.545999</td>\n",
       "      <td>-0.270424</td>\n",
       "      <td>-0.285418</td>\n",
       "      <td>-0.173447</td>\n",
       "      <td>-0.368459</td>\n",
       "      <td>2.282566</td>\n",
       "      <td>-0.177792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6266 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  education    device       day     month  time_spent  \\\n",
       "0     1.405573  -1.759765 -0.273806 -1.154049  0.726880   -1.068475   \n",
       "1     0.845879   1.258243 -0.273806 -1.293811  0.726880    0.916961   \n",
       "2     0.397833   1.258243 -0.273806  0.194014 -0.042649    0.778539   \n",
       "3    -0.907460  -0.318701 -0.273806  1.210360 -0.446910   -0.326755   \n",
       "4     0.776010  -0.318701 -0.273806 -1.293811 -0.042649   -2.338993   \n",
       "...        ...        ...       ...       ...       ...         ...   \n",
       "6261  0.231171  -1.759765  3.652215 -0.393528 -0.446910   -2.178299   \n",
       "6262 -0.038550  -1.759765 -0.273806 -0.274347 -0.446910    2.473490   \n",
       "6263  0.555253  -1.759765 -0.273806  0.309596 -0.042649   -0.639832   \n",
       "6264  1.461172  -0.318701 -0.273806  0.309596  0.726880   -0.963067   \n",
       "6265 -0.907460  -0.318701 -0.273806  0.538792  1.809339   -0.839007   \n",
       "\n",
       "      banner_views  banner_views_old  days_elapsed_old        X1  ...  \\\n",
       "0         0.335738         -0.565174         -0.565178 -0.409805  ...   \n",
       "1        -1.081376         -0.565174         -0.565178 -0.409805  ...   \n",
       "2        -1.081376         -0.565174         -0.565178 -0.409805  ...   \n",
       "3         1.352297         -0.565174         -0.565178 -0.409805  ...   \n",
       "4         0.882775         -0.565174         -0.565178 -0.409805  ...   \n",
       "...            ...               ...               ...       ...  ...   \n",
       "6261     -1.081376         -0.565174         -0.565178 -0.409805  ...   \n",
       "6262      1.352297         -0.565174         -0.565178  2.440183  ...   \n",
       "6263      0.882775         -0.565174         -0.565178 -0.409805  ...   \n",
       "6264      1.560307         -0.565174         -0.565178  2.440183  ...   \n",
       "6265      0.335738          1.780564          1.768878  2.440183  ...   \n",
       "\n",
       "      job_freelance  job_housekeeper  job_industrial_worker  job_manager  \\\n",
       "0         -0.198702         6.006407              -0.485944    -0.545999   \n",
       "1         -0.198702        -0.166489              -0.485944    -0.545999   \n",
       "2         -0.198702         6.006407              -0.485944    -0.545999   \n",
       "3         -0.198702        -0.166489               2.057852    -0.545999   \n",
       "4         -0.198702        -0.166489              -0.485944    -0.545999   \n",
       "...             ...              ...                    ...          ...   \n",
       "6261      -0.198702        -0.166489               2.057852    -0.545999   \n",
       "6262      -0.198702        -0.166489               2.057852    -0.545999   \n",
       "6263      -0.198702        -0.166489               2.057852    -0.545999   \n",
       "6264      -0.198702        -0.166489              -0.485944    -0.545999   \n",
       "6265      -0.198702        -0.166489              -0.485944    -0.545999   \n",
       "\n",
       "      job_retired  job_salesman  job_student  job_teacher  job_technology  \\\n",
       "0       -0.270424     -0.285418    -0.173447    -0.368459       -0.438103   \n",
       "1       -0.270424     -0.285418    -0.173447    -0.368459        2.282566   \n",
       "2       -0.270424     -0.285418    -0.173447    -0.368459       -0.438103   \n",
       "3       -0.270424     -0.285418    -0.173447    -0.368459       -0.438103   \n",
       "4       -0.270424     -0.285418    -0.173447     2.714005       -0.438103   \n",
       "...           ...           ...          ...          ...             ...   \n",
       "6261    -0.270424     -0.285418    -0.173447    -0.368459       -0.438103   \n",
       "6262    -0.270424     -0.285418    -0.173447    -0.368459       -0.438103   \n",
       "6263    -0.270424     -0.285418    -0.173447    -0.368459       -0.438103   \n",
       "6264     3.697901     -0.285418    -0.173447    -0.368459       -0.438103   \n",
       "6265    -0.270424     -0.285418    -0.173447    -0.368459        2.282566   \n",
       "\n",
       "      job_unemployed  \n",
       "0          -0.177792  \n",
       "1          -0.177792  \n",
       "2          -0.177792  \n",
       "3          -0.177792  \n",
       "4          -0.177792  \n",
       "...              ...  \n",
       "6261       -0.177792  \n",
       "6262       -0.177792  \n",
       "6263       -0.177792  \n",
       "6264       -0.177792  \n",
       "6265       -0.177792  \n",
       "\n",
       "[6266 rows x 31 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create interaction terms (interaction of each regressor pair + polynomial)\n",
    "#Interaction terms need to be created in both the test and train datasets\n",
    "interaction2 = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False, order='C') #second degree\n",
    "interaction3 = PolynomialFeatures(degree=3, include_bias=False, interaction_only=False, order='C') #third degree\n",
    "\n",
    "# Training\n",
    "X_train_2 = pd.DataFrame(interaction2.fit_transform(X_train), columns=interaction2.get_feature_names(input_features=X_train.columns))\n",
    "X_train_3 = pd.DataFrame(interaction3.fit_transform(X_train), columns=interaction3.get_feature_names(input_features=X_train.columns))\n",
    "X_train_2.head()\n",
    "\n",
    "# Validation\n",
    "X_valid_2 = pd.DataFrame(interaction2.fit_transform(X_valid), columns=interaction2.get_feature_names(input_features=X_valid.columns))\n",
    "X_valid_3 = pd.DataFrame(interaction3.fit_transform(X_valid), columns=interaction3.get_feature_names(input_features=X_valid.columns))\n",
    "X_valid_2.head()\n",
    "\n",
    "# Test\n",
    "X_test_2 = pd.DataFrame(interaction2.fit_transform(X_test), columns=interaction2.get_feature_names(input_features=X_test.columns))\n",
    "X_test_3 = pd.DataFrame(interaction3.fit_transform(X_test), columns=interaction3.get_feature_names(input_features=X_test.columns))\n",
    "X_test_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Normalize all datasets \n",
    "#############################\n",
    "\n",
    "power = PowerTransformer()\n",
    "\n",
    "\n",
    "# Standardize the training sets: 1st, 2nd and 3rd order polynomials\n",
    "X_train=pd.DataFrame(power.fit_transform(X_train), columns=X_train.columns)\n",
    "X_train_2=pd.DataFrame(power.fit_transform(X_train_2), columns=X_train_2.columns)\n",
    "X_train_3=pd.DataFrame(power.fit_transform(X_train_3), columns=X_train_3.columns)\n",
    "\n",
    "# Standardize the validation sets: 1st, 2nd and 3rd order polynomials\n",
    "X_valid=pd.DataFrame(power.fit_transform(X_valid), columns=X_valid.columns)\n",
    "X_valid_2=pd.DataFrame(power.fit_transform(X_valid_2), columns=X_valid_2.columns)\n",
    "X_valid_3=pd.DataFrame(power.fit_transform(X_valid_3), columns=X_valid_3.columns)\n",
    "\n",
    "# Standardize the test sets: 1st, 2nd and 3rd order polynomials\n",
    "X_test=pd.DataFrame(power.fit_transform(X_test), columns=X_test.columns)\n",
    "X_test_2=pd.DataFrame(power.fit_transform(X_test_2), columns=X_test_2.columns)\n",
    "X_test_3=pd.DataFrame(power.fit_transform(X_test_3), columns=X_test_3.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    VIF Factor      features\n",
      "0          1.0         const\n",
      "1          1.1           age\n",
      "2          1.1     education\n",
      "3          1.0        device\n",
      "4          1.0           day\n",
      "5          1.0         month\n",
      "6          1.0    time_spent\n",
      "7          1.0  banner_views\n",
      "8          1.0            X1\n",
      "9          1.0            X2\n",
      "10         1.1            X3\n",
      "11         1.1            X4\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Deal with multicollinearity\n",
    "################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#1st order polynomial ######################\n",
    "x_temp_train1 = sm.add_constant(X_train)\n",
    "vif_train1 = pd.DataFrame()\n",
    "vif_train1[\"VIF Factor\"] = [variance_inflation_factor(x_temp_train1.values, i) for i in range(x_temp_train1.values.shape[1])]\n",
    "vif_train1[\"features\"] = x_temp_train1.columns\n",
    "pd.set_option('display.max_rows', 300)\n",
    "print(vif_train1.round(1))\n",
    "\n",
    "# Identify all variables wit VIF less then 5 and keep\n",
    "vif_train1_a=vif_train1[vif_train1[\"VIF Factor\"]<5.0]  # print(vif2.round(1))\n",
    "\n",
    "feat_list=vif_train1_a[\"features\"].tolist()  #save desired features to list\n",
    "feat_list.remove(feat_list[0])\n",
    "print(feat_list)\n",
    "\n",
    "X_train=X_train[feat_list] #keep features on feature list only, drop all other features for train\n",
    "X_valid=X_valid[feat_list] #keep features on feature list only, drop all other features for valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emann\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day', 'month', 'time_spent', 'banner_views', 'X4', 'age^2', 'age education', 'age device', 'age day', 'age month', 'age time_spent', 'age banner_views', 'age X1', 'age X2', 'age X3', 'age X4', 'age job_entrepreneur', 'age job_housekeeper', 'age job_unemployed', 'education device', 'education day', 'education month', 'education time_spent', 'education banner_views', 'education X1', 'education X2', 'education X3', 'education X4', 'education job_entrepreneur', 'education job_freelance', 'education job_housekeeper', 'education job_salesman', 'education job_student', 'education job_teacher', 'education job_unemployed', 'device day', 'device month', 'device time_spent', 'device banner_views', 'device X1', 'device X2', 'device X3', 'device X4', 'day month', 'day time_spent', 'day banner_views', 'day X1', 'day X2', 'day X3', 'day X4', 'month^2', 'month time_spent', 'month banner_views', 'month X1', 'month X2', 'month X3', 'month X4', 'time_spent^2', 'time_spent banner_views', 'time_spent X1', 'time_spent X2', 'time_spent X3', 'time_spent X4', 'banner_views^2', 'banner_views X1', 'banner_views X2', 'banner_views X3', 'banner_views X4', 'X1 X2', 'X1 X3', 'X1 X4', 'X2 X3', 'X2 X4', 'X3 X4', 'X4^2', 'X4 job_entrepreneur', 'X4 job_freelance', 'X4 job_housekeeper', 'X4 job_student', 'X4 job_unemployed']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>banner_views</th>\n",
       "      <th>X4</th>\n",
       "      <th>age^2</th>\n",
       "      <th>age education</th>\n",
       "      <th>age device</th>\n",
       "      <th>age day</th>\n",
       "      <th>age month</th>\n",
       "      <th>...</th>\n",
       "      <th>X1 X4</th>\n",
       "      <th>X2 X3</th>\n",
       "      <th>X2 X4</th>\n",
       "      <th>X3 X4</th>\n",
       "      <th>X4^2</th>\n",
       "      <th>X4 job_entrepreneur</th>\n",
       "      <th>X4 job_freelance</th>\n",
       "      <th>X4 job_housekeeper</th>\n",
       "      <th>X4 job_student</th>\n",
       "      <th>X4 job_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.284243</td>\n",
       "      <td>0.718975</td>\n",
       "      <td>-1.004293</td>\n",
       "      <td>1.572205</td>\n",
       "      <td>0.924993</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>1.657017</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>1.649631</td>\n",
       "      <td>1.164174</td>\n",
       "      <td>...</td>\n",
       "      <td>2.682420</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>-0.974720</td>\n",
       "      <td>0.819998</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.380305</td>\n",
       "      <td>-0.460421</td>\n",
       "      <td>-0.864125</td>\n",
       "      <td>1.424980</td>\n",
       "      <td>-0.586173</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>-0.164368</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>1.042586</td>\n",
       "      <td>-0.379500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372962</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>0.864696</td>\n",
       "      <td>-0.607027</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>5.251140</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.459908</td>\n",
       "      <td>1.814169</td>\n",
       "      <td>0.796361</td>\n",
       "      <td>0.271268</td>\n",
       "      <td>2.088788</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>-1.880754</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>0.537626</td>\n",
       "      <td>2.776608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372962</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>-0.974720</td>\n",
       "      <td>2.323232</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.212258</td>\n",
       "      <td>-0.460421</td>\n",
       "      <td>-0.700354</td>\n",
       "      <td>0.271268</td>\n",
       "      <td>-0.244794</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>-1.880754</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-0.266227</td>\n",
       "      <td>-0.467486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372962</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>0.914515</td>\n",
       "      <td>-0.326669</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.569285</td>\n",
       "      <td>0.337028</td>\n",
       "      <td>-1.391977</td>\n",
       "      <td>1.946463</td>\n",
       "      <td>-0.631736</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>-0.611975</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>0.424628</td>\n",
       "      <td>-0.512616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372962</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>0.858466</td>\n",
       "      <td>-0.642970</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>1.475304</td>\n",
       "      <td>-2.282042</td>\n",
       "      <td>-0.387055</td>\n",
       "      <td>-1.037391</td>\n",
       "      <td>0.396987</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>-0.132164</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>1.161026</td>\n",
       "      <td>-2.330341</td>\n",
       "      <td>...</td>\n",
       "      <td>2.682066</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>1.028076</td>\n",
       "      <td>0.261388</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>-0.588697</td>\n",
       "      <td>-1.319180</td>\n",
       "      <td>-0.069579</td>\n",
       "      <td>-1.037391</td>\n",
       "      <td>1.251139</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>0.521628</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>0.103492</td>\n",
       "      <td>-0.440780</td>\n",
       "      <td>...</td>\n",
       "      <td>2.682578</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>1.257447</td>\n",
       "      <td>1.207462</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1.187066</td>\n",
       "      <td>0.718975</td>\n",
       "      <td>-0.677663</td>\n",
       "      <td>1.678829</td>\n",
       "      <td>-0.935608</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>1.275583</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>1.228224</td>\n",
       "      <td>0.810170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372962</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>-0.974720</td>\n",
       "      <td>-0.874559</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0.577133</td>\n",
       "      <td>-0.055479</td>\n",
       "      <td>-2.492769</td>\n",
       "      <td>0.871798</td>\n",
       "      <td>0.890611</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>1.076677</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>0.573011</td>\n",
       "      <td>0.066817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372962</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>1.143923</td>\n",
       "      <td>0.781181</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>-1.303095</td>\n",
       "      <td>-1.319180</td>\n",
       "      <td>0.246704</td>\n",
       "      <td>-1.037391</td>\n",
       "      <td>1.985865</td>\n",
       "      <td>6.800116e-16</td>\n",
       "      <td>0.871375</td>\n",
       "      <td>-0.266407</td>\n",
       "      <td>-1.257577</td>\n",
       "      <td>-1.178401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372962</td>\n",
       "      <td>-0.082138</td>\n",
       "      <td>-0.102636</td>\n",
       "      <td>-0.974720</td>\n",
       "      <td>2.200749</td>\n",
       "      <td>-0.179674</td>\n",
       "      <td>-0.190435</td>\n",
       "      <td>-0.188325</td>\n",
       "      <td>-0.196646</td>\n",
       "      <td>-0.17521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1343 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           day     month  time_spent  banner_views        X4         age^2  \\\n",
       "0     1.284243  0.718975   -1.004293      1.572205  0.924993  6.800116e-16   \n",
       "1     1.380305 -0.460421   -0.864125      1.424980 -0.586173  6.800116e-16   \n",
       "2    -0.459908  1.814169    0.796361      0.271268  2.088788  6.800116e-16   \n",
       "3    -0.212258 -0.460421   -0.700354      0.271268 -0.244794  6.800116e-16   \n",
       "4     1.569285  0.337028   -1.391977      1.946463 -0.631736  6.800116e-16   \n",
       "...        ...       ...         ...           ...       ...           ...   \n",
       "1338  1.475304 -2.282042   -0.387055     -1.037391  0.396987  6.800116e-16   \n",
       "1339 -0.588697 -1.319180   -0.069579     -1.037391  1.251139  6.800116e-16   \n",
       "1340  1.187066  0.718975   -0.677663      1.678829 -0.935608  6.800116e-16   \n",
       "1341  0.577133 -0.055479   -2.492769      0.871798  0.890611  6.800116e-16   \n",
       "1342 -1.303095 -1.319180    0.246704     -1.037391  1.985865  6.800116e-16   \n",
       "\n",
       "      age education  age device   age day  age month  ...     X1 X4     X2 X3  \\\n",
       "0          1.657017   -0.266407  1.649631   1.164174  ...  2.682420 -0.082138   \n",
       "1         -0.164368   -0.266407  1.042586  -0.379500  ... -0.372962 -0.082138   \n",
       "2         -1.880754   -0.266407  0.537626   2.776608  ... -0.372962 -0.082138   \n",
       "3         -1.880754   -0.266407 -0.266227  -0.467486  ... -0.372962 -0.082138   \n",
       "4         -0.611975   -0.266407  0.424628  -0.512616  ... -0.372962 -0.082138   \n",
       "...             ...         ...       ...        ...  ...       ...       ...   \n",
       "1338      -0.132164   -0.266407  1.161026  -2.330341  ...  2.682066 -0.082138   \n",
       "1339       0.521628   -0.266407  0.103492  -0.440780  ...  2.682578 -0.082138   \n",
       "1340       1.275583   -0.266407  1.228224   0.810170  ... -0.372962 -0.082138   \n",
       "1341       1.076677   -0.266407  0.573011   0.066817  ... -0.372962 -0.082138   \n",
       "1342       0.871375   -0.266407 -1.257577  -1.178401  ... -0.372962 -0.082138   \n",
       "\n",
       "         X2 X4     X3 X4      X4^2  X4 job_entrepreneur  X4 job_freelance  \\\n",
       "0    -0.102636 -0.974720  0.819998            -0.179674         -0.190435   \n",
       "1    -0.102636  0.864696 -0.607027            -0.179674          5.251140   \n",
       "2    -0.102636 -0.974720  2.323232            -0.179674         -0.190435   \n",
       "3    -0.102636  0.914515 -0.326669            -0.179674         -0.190435   \n",
       "4    -0.102636  0.858466 -0.642970            -0.179674         -0.190435   \n",
       "...        ...       ...       ...                  ...               ...   \n",
       "1338 -0.102636  1.028076  0.261388            -0.179674         -0.190435   \n",
       "1339 -0.102636  1.257447  1.207462            -0.179674         -0.190435   \n",
       "1340 -0.102636 -0.974720 -0.874559            -0.179674         -0.190435   \n",
       "1341 -0.102636  1.143923  0.781181            -0.179674         -0.190435   \n",
       "1342 -0.102636 -0.974720  2.200749            -0.179674         -0.190435   \n",
       "\n",
       "      X4 job_housekeeper  X4 job_student  X4 job_unemployed  \n",
       "0              -0.188325       -0.196646           -0.17521  \n",
       "1              -0.188325       -0.196646           -0.17521  \n",
       "2              -0.188325       -0.196646           -0.17521  \n",
       "3              -0.188325       -0.196646           -0.17521  \n",
       "4              -0.188325       -0.196646           -0.17521  \n",
       "...                  ...             ...                ...  \n",
       "1338           -0.188325       -0.196646           -0.17521  \n",
       "1339           -0.188325       -0.196646           -0.17521  \n",
       "1340           -0.188325       -0.196646           -0.17521  \n",
       "1341           -0.188325       -0.196646           -0.17521  \n",
       "1342           -0.188325       -0.196646           -0.17521  \n",
       "\n",
       "[1343 rows x 80 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2nd order polynomial ####################\n",
    "x_temp_train2 = sm.add_constant(X_train_2)\n",
    "vif_train2 = pd.DataFrame()\n",
    "vif_train2[\"VIF Factor\"] = [variance_inflation_factor(x_temp_train2.values, i) for i in range(x_temp_train2.values.shape[1])]\n",
    "vif_train2[\"features\"] = x_temp_train2.columns\n",
    "pd.set_option('display.max_rows', 300)\n",
    "#print(vif_train1.round(1))\n",
    "\n",
    "vif_train2_a=vif_train2[vif_train2[\"VIF Factor\"]<5.0]\n",
    "#print(vif2.round(1))\n",
    "\n",
    "feat_list2=vif_train2_a[\"features\"].tolist()\n",
    "feat_list2.remove(feat_list2[0])\n",
    "print(feat_list2)\n",
    "\n",
    "X_train_2=X_train_2[feat_list2] #keep features on feature list only, drop all other features for train\n",
    "X_valid_2=X_valid_2[feat_list2] #keep features on feature list only, drop all other features for valid\n",
    "X_valid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd order polynomial ####################\n",
    "x_temp_train3 = sm.add_constant(X_train_3)\n",
    "vif_train3 = pd.DataFrame()\n",
    "vif_train3[\"VIF Factor\"] = [variance_inflation_factor(x_temp_train3.values, i) for i in range(x_temp_train3.values.shape[1])]\n",
    "vif_train3[\"features\"] = x_temp_train3.columns\n",
    "pd.set_option('display.max_rows', 300)\n",
    "#print(vif_train3.round(1))\n",
    "\n",
    "vif_train3_a=vif_train3[vif_train3[\"VIF Factor\"]<5.0]\n",
    "#print(vif3.round(1))\n",
    "\n",
    "feat_list3=vif_train3_a[\"features\"].tolist()\n",
    "feat_list3.remove(feat_list3[0])\n",
    "print(feat_list3)\n",
    "\n",
    "X_train_3=X_train_3[feat_list3] #keep features on feature list only, drop all other features for train\n",
    "X_valid_3=X_valid_3[feat_list3]   #keep features on feature list only, drop all other features for valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default LDA model without any tuning - base metric\n",
    "LDA_model_default = LinearDiscriminantAnalysis()\n",
    "LDA_model_default.fit(X_train, y_train)\n",
    "y_pred_LDA_default =LDA_model_default.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
