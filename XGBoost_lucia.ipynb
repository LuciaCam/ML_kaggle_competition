{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `xgboost` module is a popular implementation of tree boosting. One of its main differences with the regular boosting introduced in class is the presence of a regularization term directly in the objective function to minimize. The following discussion is based on [XGBoost's documentation](https://xgboost.readthedocs.io/en/stable/index.html) and [Chen, T., & Guestrin, C. (2016, August). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining (pp. 785-794).](https://arxiv.org/pdf/1603.02754.pdf)\n",
    "\n",
    "We recall that as we have seen the final boosted model is a sum of $B$ trees which can be written as\n",
    "\n",
    "$$\\hat{f}(x) = \\sum_{b=1}^B \\hat{f}^b(x)$$\n",
    "\n",
    "In classical boosting, during training the model is minimizing\n",
    "\n",
    "$$\\mathcal{L}(\\hat{f}) = \\sum_{i=1}^n \\eta L(\\hat{y}_i, y_i) \\quad \\quad \\text{where } \\hat{y}_i = \\hat{f}(x_i)$$\n",
    "\n",
    "Here, $\\eta \\in (0,1)$ is the shrinkage parameter and $L$ is the loss function. For regression, this is typically the squared error loss, whereas for classification, this could be the maximum likelihood loss. XGBoost, on the other hand, introduces a second term in the objective to minimize, which can then be rewritten as\n",
    "\n",
    "$$\\mathcal{L}(\\hat{f}) = \\sum_{i=1}^n \\eta L(\\hat{y}_i, y_i) + \\sum_{b=1}^B \\Omega(\\hat{f}^b) \\quad \\quad\n",
    "\\text{where }\\Omega(f) = \\gamma T + \\dfrac{1}{2} \\lambda ||w||^2$$\n",
    "\n",
    "The parameters used in the regularization function $\\Omega$ are listed below:\n",
    "- $T$ is the number of leaves of the tree. This penalizes bigger leaf numbers, which means trees which are more complex.\n",
    "- $w \\in \\mathbb{R}^T$ are the weights which are assigned in each leaf of the tree. The weights are the predicted outputs in each leaf. They are real values if we have a regression tree, and probabilities if we have a decision tree.\n",
    "- $\\gamma \\geq 0$ and $\\lambda \\geq 0$ are penalty terms, akin to parameter $\\lambda$ in ridge or lasso linear regression, for example. The bigger their values, the stronger the regularization is. They are tuning parameters.\n",
    "\n",
    "\n",
    "The implementation of regularization directly in the objective function helps to avoid overfitting which can happen easily when using boosting methods. XGBoost also provides a lot of other improvements from a point of view of computational efficiency. We will not get in the details as their are more directly related to computer science, however some aspects will be alluded to later when discussing all the tuning parameters we have used to build our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the data and split it into predictors `X` and response `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_ad = pd.read_csv(\"MLUnige2023_subscriptions_train.csv\", index_col=\"Id\")\n",
    "campaign_test = pd.read_csv(\"MLUnige2023_subscriptions_test.csv\", index_col=\"Id\")\n",
    "\n",
    "X = campaign_ad.drop(columns='subscription')\n",
    "y = campaign_ad['subscription']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost can handle categorical variables, but their `dtype` must be converted to `category`. We do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical variables\n",
    "num_vars = ['age', 'time_spent', 'banner_views', 'banner_views_old', 'days_elapsed_old', 'X4']\n",
    "# categorical variables\n",
    "cat_vars = list(set(X.columns).difference(num_vars))\n",
    "\n",
    "# converting type to category\n",
    "for col in cat_vars:\n",
    "  X[col] = X[col].astype(\"category\")\n",
    "  campaign_test[col] = campaign_test[col].astype(\"category\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split `X` and `y` into training, validation and test sets. The seeds are indentical to the ones used with other models to ensure that we have a fair ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=46)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our `xgb_clf` below with the following parameters:\n",
    "- `tree_method` is set to `'hist'`. One of the particularities implemented by XGBoost is that when choosing the next best split for a tree, instead of sorting all values of each predictor and go through them to determine where the optimal split should occur, the algorithm will create an histogram which approximates the distribution of the predictor. This makes the whole process much more fast.\n",
    "- `objective` is set to `'binary:logistic'`. This is the appropriate objective function when dealing with a classification task in which the outome variable is binary.\n",
    "- `eval_metric` is set to `'auc'`. In classification, a commonly used visualization to assess model performance is the ROC curve, which plots the True Positive Rate against the False Positive Rate. A model which performs well should have a curve which increases as steeply and quickly as possible. Thus, a possible measure used to assess the model performance is the area under the ROC curve, which is called AUC. A bigger area means that the model is performing better. The maximum area of the ROC curve is 1. The AUC is handy, as it does not depend on the choice of probablility cutoff for classifying records as 0 or 1.\n",
    "- `enable_categorical` is set to `True`. This is necessary if there are categorical predictors, so that XGBoost correctly handles them.\n",
    "- `n_jobs` is set to `-2`. This parameter enambles portions of the algorithm to be run in parallel on multiple cores of the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(tree_method='hist',\n",
    "                        objective='binary:logistic',\n",
    "                        eval_metric='auc',\n",
    "                        enable_categorical=True,\n",
    "                        n_jobs=-2,\n",
    "                        random_state=391)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a parameter grid for our parameter search. We explain the tuning parameters which are used below:\n",
    "- `n_estimators` is the number of trees $B$.\n",
    "- `max_depth` is the maximum depth allowed for all trees.\n",
    "- `learning_rate` is the shrinkage parameter $\\eta$.\n",
    "- `colsample_bytree` is the proportion of the total features which are used to grow each tree. For example, if it is equal to 0.5, it means that for each tree, only half the predictors are randomly picked among all possible features. Thus, each tree has its own combination of predictors. By default, it is set to 1.\n",
    "- `gamma` is the penalty parameter $\\gamma$ defined inside regularization function $\\Omega$.\n",
    "- `reg_lambda` is the penalty parameter $\\lambda$ defined inside regularization function $\\Omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search = {'n_estimators': range(50, 301),\n",
    "                'max_depth': range(1, 8),\n",
    "                'learning_rate': stats.uniform(0.001, 0.3),   # [0.001, 0.301]\n",
    "                'colsample_bytree': stats.uniform(0.5, 0.5),  # [0.5, 1]\n",
    "                'gamma': stats.uniform(0, 0.5),               # [0, 0.5]\n",
    "                'reg_lambda': stats.uniform(0, 5)             # [0, 5]\n",
    "                }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above grid, for continuous tuning parameters, we used a uniform distribution inside an interval instead of a list of values. This is because we are going to use `RandomizedSearchCV` instead of the classical grid search. This gridsearch will generate random values from the distributions we provided. To do so, in each fold it will go through a number `n_iter` of iterations taken from the grid we constructed. We have chosen to use the `StratifiedKFold` function which creates folds which all have a similar proportion of positive responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 250 candidates, totalling 1250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-54 {color: black;background-color: white;}#sk-container-id-54 pre{padding: 0;}#sk-container-id-54 div.sk-toggleable {background-color: white;}#sk-container-id-54 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-54 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-54 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-54 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-54 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-54 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-54 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-54 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-54 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-54 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-54 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-54 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-54 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-54 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-54 div.sk-item {position: relative;z-index: 1;}#sk-container-id-54 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-54 div.sk-item::before, #sk-container-id-54 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-54 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-54 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-54 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-54 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-54 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-54 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-54 div.sk-label-container {text-align: center;}#sk-container-id-54 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-54 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-54\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=611, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=True,\n",
       "                                           eval_metric=&#x27;auc&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importa...\n",
       "                                        &#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a89709a0&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a8916df0&gt;,\n",
       "                                        &#x27;max_depth&#x27;: range(1, 8),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 301),\n",
       "                                        &#x27;reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8aa9cbdf0&gt;},\n",
       "                   random_state=3989, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=611, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=True,\n",
       "                                           eval_metric=&#x27;auc&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importa...\n",
       "                                        &#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a89709a0&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a8916df0&gt;,\n",
       "                                        &#x27;max_depth&#x27;: range(1, 8),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 301),\n",
       "                                        &#x27;reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8aa9cbdf0&gt;},\n",
       "                   random_state=3989, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-2, num_parallel_tree=None,\n",
       "              predictor=None, random_state=391, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-2, num_parallel_tree=None,\n",
       "              predictor=None, random_state=391, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=611, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=True,\n",
       "                                           eval_metric='auc',\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importa...\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a89709a0>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a8916df0>,\n",
       "                                        'max_depth': range(1, 8),\n",
       "                                        'n_estimators': range(50, 301),\n",
       "                                        'reg_lambda': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8aa9cbdf0>},\n",
       "                   random_state=3989, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomizedSearchCV(xgb_clf,\n",
    "                           param_distributions=param_search,\n",
    "                           n_iter=250,\n",
    "                           scoring='roc_auc',\n",
    "                           verbose=1,\n",
    "                           cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=611),\n",
    "                           random_state=3989)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the best parameters from our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5771695955273806,\n",
       " 'gamma': 0.004545655718141806,\n",
       " 'learning_rate': 0.06939821015677476,\n",
       " 'max_depth': 7,\n",
       " 'n_estimators': 270,\n",
       " 'reg_lambda': 1.0061012533676594}"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = model.best_params_\n",
    "best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the AUC of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308282426468221"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good score, as the maximal value of the AUC is 1. Now, we can use the best parameters to fit our XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-60 {color: black;background-color: white;}#sk-container-id-60 pre{padding: 0;}#sk-container-id-60 div.sk-toggleable {background-color: white;}#sk-container-id-60 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-60 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-60 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-60 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-60 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-60 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-60 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-60 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-60 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-60 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-60 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-60 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-60 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-60 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-60 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-60 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-60 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-60 div.sk-item {position: relative;z-index: 1;}#sk-container-id-60 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-60 div.sk-item::before, #sk-container-id-60 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-60 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-60 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-60 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-60 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-60 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-60 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-60 div.sk-label-container {text-align: center;}#sk-container-id-60 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-60 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-60\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5771695955273806, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=0.004545655718141806, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.06939821015677476, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=270, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-106\" type=\"checkbox\" checked><label for=\"sk-estimator-id-106\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5771695955273806, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=0.004545655718141806, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.06939821015677476, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=270, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5771695955273806, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric='auc', feature_types=None,\n",
       "              gamma=0.004545655718141806, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.06939821015677476, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=270, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(**best_params,\n",
    "                          tree_method='hist',\n",
    "                          objective='binary:logistic',\n",
    "                          eval_metric='auc',\n",
    "                          enable_categorical=True)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the accuracy scores on the training, validation and test sets of the model. We also compute it on `campaign_ad`as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train: 0.984360038301947\n",
      "Accuracy on valid: 0.9888309754281459\n",
      "Accuracy on test: 0.9843633655994043\n",
      "Accuracy on campaign_ad: 0.9850312779267203\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = xgb_model.predict(X_train)\n",
    "print('Accuracy on train:', accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "y_valid_pred = xgb_model.predict(X_valid)\n",
    "print('Accuracy on valid:', accuracy_score(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "print('Accuracy on test:', accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "y_pred = xgb_model.predict(X)\n",
    "print('Accuracy on campaign_ad:', accuracy_score(y, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the model on the whole `campaign_ad` dataset before generating the prediction for `campaign_test`. We also display the accuracy of the model on `campaign_ad` once it is fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on campaign_ad for model trained on campaign_ad: 0.9850312779267203\n"
     ]
    }
   ],
   "source": [
    "xgb_model.fit(X, y)\n",
    "y_pred = xgb_model.predict(X)\n",
    "print('Accuracy on campaign_ad for model trained on campaign_ad:', accuracy_score(y, y_pred))\n",
    "\n",
    "y_REAL_test = xgb_model.predict(campaign_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write the computed predictions `y_REAL_test` into a CSV file which is then uploaded onto kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test_file_xgboost.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['Id', 'subscription'])\n",
    "for i in range(len(y_REAL_test)):\n",
    "    writer.writerow([i, y_REAL_test[i]])\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
