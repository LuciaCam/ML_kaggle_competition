{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `xgboost` module is a popular implementation of tree boosting. One of its main differences with the regular boosting introduced in class is the presence of a regularization term directly in the objective function to minimize. The following discussion is based on [XGBoost's documentation](https://xgboost.readthedocs.io/en/stable/index.html) and [Chen, T., & Guestrin, C. (2016, August). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining (pp. 785-794).](https://arxiv.org/pdf/1603.02754.pdf)\n",
    "\n",
    "We recall that as we have seen the final boosted model is a sum of $B$ trees which can be written as\n",
    "\n",
    "$$\\hat{f}(x) = \\sum_{b=1}^B \\hat{f}^b(x)$$\n",
    "\n",
    "In classical boosting, during training the model is minimizing\n",
    "\n",
    "$$\\mathcal{L}(\\hat{f}) = \\sum_{i=1}^n \\eta L(\\hat{y}_i, y_i) \\quad \\quad \\text{where } \\hat{y}_i = \\hat{f}(x_i)$$\n",
    "\n",
    "Here, $\\eta \\in (0,1)$ is the shrinkage parameter and $L$ is the loss function. For regression, this is typically the squared error loss, whereas for classification, this could be the maximum likelihood loss. XGBoost, on the other hand, introduces a second term in the objective to minimize, which can then be rewritten as\n",
    "\n",
    "$$\\mathcal{L}(\\hat{f}) = \\sum_{i=1}^n \\eta L(\\hat{y}_i, y_i) + \\sum_{b=1}^B \\Omega(\\hat{f}^b) \\quad \\quad\n",
    "\\text{where }\\Omega(f) = \\gamma T + \\dfrac{1}{2} \\lambda ||w||^2$$\n",
    "\n",
    "The parameters used in the regularization function $\\Omega$ are listed below:\n",
    "- $T$ is the number of leaves of the tree. This penalizes bigger leaf numbers, which means trees which are more complex.\n",
    "- $w \\in \\mathbb{R}^T$ are the weights which are assigned in each leaf of the tree. The weights are the predicted outputs in each leaf. They are real values if we have a regression tree, and probabilities if we have a decision tree.\n",
    "- $\\gamma \\geq 0$ and $\\lambda \\geq 0$ are penalty terms, akin to parameter $\\lambda$ in ridge or lasso linear regression, for example. The bigger their values, the stronger the regularization is. They are tuning parameters.\n",
    "\n",
    "\n",
    "The implementation of regularization directly in the objective function helps to avoid overfitting which can happen easily when using boosting methods. XGBoost also provides a lot of other improvements from a point of view of computational efficiency. We will not get in the details as their are more directly related to computer science, however some aspects will be alluded to later when discussing all the tuning parameters we have used to build our model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the data and split it into predictors `X` and response `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_ad = pd.read_csv(\"MLUnige2023_subscriptions_train.csv\", index_col=\"Id\")\n",
    "campaign_test = pd.read_csv(\"MLUnige2023_subscriptions_test.csv\", index_col=\"Id\")\n",
    "\n",
    "X = campaign_ad.drop(columns='subscription')\n",
    "y = campaign_ad['subscription']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost can handle categorical variables, but their `dtype` must be converted to `category`. We do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical variables\n",
    "num_vars = ['age', 'time_spent', 'banner_views', 'banner_views_old', 'days_elapsed_old', 'X4']\n",
    "# categorical variables\n",
    "cat_vars = list(set(X.columns).difference(num_vars))\n",
    "\n",
    "# converting type to category\n",
    "for col in cat_vars:\n",
    "  X[col] = X[col].astype(\"category\")\n",
    "  campaign_test[col] = campaign_test[col].astype(\"category\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split `X` and `y` into training, validation and test sets. The seeds are indentical to the ones used with other models to ensure that we have a fair ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=46)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our `xgb_clf` below with the following parameters:\n",
    "- `tree_method` is set to `'hist'`. One of the particularities implemented by XGBoost is that when choosing the next best split for a tree, instead of sorting all values of each predictor and go through them to determine where the optimal split should occur, the algorithm will create an histogram which approximates the distribution of the predictor. This makes the whole process much more fast.\n",
    "- `objective` is set to `'binary:logistic'`. This is the appropriate objective function when dealing with a classification task in which the outome variable is binary.\n",
    "- `eval_metric` is set to `'auc'`. In classification, a commonly used visualization to assess model performance is the ROC curve, which plots the True Positive Rate against the False Positive Rate. A model which performs well should have a curve which increases as steeply and quickly as possible. Thus, a possible measure used to assess the model performance is the area under the ROC curve, which is called AUC. A bigger area means that the model is performing better. The AUC is handy, as it does not depend on the choice of probablility cutoff for classifying records as 0 or 1.\n",
    "- `enable_categorical` is set to `True`. This is necessary if there are categorical predictors, so that XGBoost correctly handles them.\n",
    "- `n_jobs` is set to `-2`. This parameter enambles portions of the algorithm to be run in parallel on multiple cores of the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(tree_method='hist',\n",
    "                        objective='binary:logistic',\n",
    "                        eval_metric='auc',\n",
    "                        enable_categorical=True,\n",
    "                        n_jobs=-2,\n",
    "                        random_state=391)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a parameter grid for our parameter search. We explain the tuning parameters which are used below:\n",
    "- `n_estimators` is the number of trees $B$.\n",
    "- `max_depth` is the maximum depth allowed for all trees.\n",
    "- `learning_rate` is the shrinkage parameter $\\eta$.\n",
    "- `gamma` is the penalty parameter $\\gamma$ defined inside regularization function $\\Omega$.\n",
    "- `reg_lambda` is the penalty parameter $\\lambda$ defined inside regularization function $\\Omega$.\n",
    "\n",
    "We also incorporated the two following parameters in early grid searches, but their ideal values were remaining close the the default ones, so we decided to keep them are their default.\n",
    "- `colsample_bytree` is the proportion of the total features which are used to grow each tree. For example, if it is equal to 0.5, it means that for each tree, only half the predictors are randomly picked among all possible features. Thus, each tree has its own combination of predictors. By default, it is set to 1.\n",
    "- `scale_pos_weight` is the balancing of weights. By default, it is set to 1, which means that when considering the response `subscription`, 1 and 0 are weighted symmetrically. If the ratio is bigger than 1, more importance is given to the positive class, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search = {'n_estimators': range(50, 301),\n",
    "                'max_depth': range(1, 8),\n",
    "                'learning_rate': stats.uniform(0.001, 0.3),   # [0.001, 0.301]\n",
    "                'colsample_bytree': stats.uniform(0.5, 0.5),  # [0.5, 1]\n",
    "                'gamma': stats.uniform(0, 0.5),               # [0, 0.5]\n",
    "                'reg_lambda': stats.uniform(0, 5)             # [0, 5]\n",
    "                }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above grid, for continuous tuning parameters, we used a uniform distribution inside an interval instead of a list of values. This is because we are going to use `RandomizedSearchCV` instead of the classical grid search. This gridsearch will generate random values from the distributions we provided. To do so, in each fold it will go through a number `n_iter` of iterations taken from the grid we constructed. We have chosen to use the `StratifiedKFold` function which creates folds which all have a similar proportion of positive responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 250 candidates, totalling 1250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-41 {color: black;background-color: white;}#sk-container-id-41 pre{padding: 0;}#sk-container-id-41 div.sk-toggleable {background-color: white;}#sk-container-id-41 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-41 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-41 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-41 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-41 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-41 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-41 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-41 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-41 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-41 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-41 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-41 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-41 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-41 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-41 div.sk-item {position: relative;z-index: 1;}#sk-container-id-41 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-41 div.sk-item::before, #sk-container-id-41 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-41 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-41 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-41 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-41 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-41 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-41 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-41 div.sk-label-container {text-align: center;}#sk-container-id-41 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-41 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-41\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=611, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=True,\n",
       "                                           eval_metric=&#x27;auc&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importa...\n",
       "                                        &#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a0a8c0d0&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a8a350a0&gt;,\n",
       "                                        &#x27;max_depth&#x27;: range(1, 8),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 301),\n",
       "                                        &#x27;reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a2362e50&gt;},\n",
       "                   random_state=37, return_train_score=True, scoring=&#x27;roc_auc&#x27;,\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=611, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=True,\n",
       "                                           eval_metric=&#x27;auc&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importa...\n",
       "                                        &#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a0a8c0d0&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a8a350a0&gt;,\n",
       "                                        &#x27;max_depth&#x27;: range(1, 8),\n",
       "                                        &#x27;n_estimators&#x27;: range(50, 301),\n",
       "                                        &#x27;reg_lambda&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a2362e50&gt;},\n",
       "                   random_state=37, return_train_score=True, scoring=&#x27;roc_auc&#x27;,\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-2, num_parallel_tree=None,\n",
       "              predictor=None, random_state=391, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-2, num_parallel_tree=None,\n",
       "              predictor=None, random_state=391, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=611, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=True,\n",
       "                                           eval_metric='auc',\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importa...\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a0a8c0d0>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a8a350a0>,\n",
       "                                        'max_depth': range(1, 8),\n",
       "                                        'n_estimators': range(50, 301),\n",
       "                                        'reg_lambda': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fd8a2362e50>},\n",
       "                   random_state=37, return_train_score=True, scoring='roc_auc',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomizedSearchCV(xgb_clf,\n",
    "                           param_distributions=param_search,\n",
    "                           n_iter=250,\n",
    "                           scoring='roc_auc',\n",
    "                           return_train_score=True,\n",
    "                           verbose=1,\n",
    "                           cv= StratifiedKFold(n_splits=5, shuffle=True, random_state=611),\n",
    "                           random_state=37)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the best parameters from our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.635562621004793,\n",
       " 'gamma': 0.4165486523112224,\n",
       " 'learning_rate': 0.04689135859111069,\n",
       " 'max_depth': 7,\n",
       " 'n_estimators': 261,\n",
       " 'reg_lambda': 3.8384092245326618}"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = model.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'colsample_bytree': 0.9605195575049101,\n",
    " 'gamma': 0.2780067362138148,\n",
    " 'learning_rate': 0.16146905484916832,\n",
    " 'max_depth': 6,\n",
    " 'n_estimators': 114,\n",
    " 'scale_pos_weight': 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the accuracy of the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9316474777096093"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-42 {color: black;background-color: white;}#sk-container-id-42 pre{padding: 0;}#sk-container-id-42 div.sk-toggleable {background-color: white;}#sk-container-id-42 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-42 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-42 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-42 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-42 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-42 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-42 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-42 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-42 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-42 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-42 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-42 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-42 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-42 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-42 div.sk-item {position: relative;z-index: 1;}#sk-container-id-42 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-42 div.sk-item::before, #sk-container-id-42 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-42 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-42 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-42 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-42 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-42 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-42 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-42 div.sk-label-container {text-align: center;}#sk-container-id-42 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-42 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-42\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.635562621004793, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=0.4165486523112224, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.04689135859111069, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=261, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" checked><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.635562621004793, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=0.4165486523112224, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.04689135859111069, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=261, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.635562621004793, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric='auc', feature_types=None,\n",
       "              gamma=0.4165486523112224, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.04689135859111069, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=261, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(**best_params,\n",
    "                          tree_method='hist',\n",
    "                          objective='binary:logistic',\n",
    "                          eval_metric='auc',\n",
    "                          enable_categorical=True)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = xgb_model.predict_proba(X_train)[:,1]\n",
    "valid_pred = xgb_model.predict_proba(X_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cutoff  train_acc  valid_acc\n",
       "0     0.10      0.838      0.792\n",
       "1     0.15      0.874      0.812\n",
       "2     0.20      0.902      0.830\n",
       "3     0.25      0.922      0.838\n",
       "4     0.30      0.935      0.846\n",
       "5     0.35      0.947      0.851\n",
       "6     0.40      0.954      0.847\n",
       "7     0.45      0.959      0.850\n",
       "8     0.50      0.964      0.845\n",
       "9     0.55      0.965      0.847\n",
       "10    0.60      0.965      0.844\n",
       "11    0.65      0.958      0.841\n",
       "12    0.70      0.949      0.832\n",
       "13    0.75      0.932      0.821\n",
       "14    0.80      0.911      0.799\n",
       "15    0.85      0.879      0.764\n",
       "16    0.90      0.812      0.730"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_table = pd.DataFrame({'cutoff': 1e-2*np.arange(10, 95, 5)})\n",
    "cutoff_table['train_acc'] = [np.round(accuracy_score(y_train, (train_pred > cutoff).astype(int)), 3)\n",
    "                             for cutoff in cutoff_table['cutoff']]\n",
    "cutoff_table['valid_acc'] = [np.round(accuracy_score(y_valid, (valid_pred > cutoff).astype(int)), 3)\n",
    "                             for cutoff in cutoff_table['cutoff']]\n",
    "cutoff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.8459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>0.8466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.9397</td>\n",
       "      <td>0.8474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>0.8474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>0.8511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.8511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.8526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>0.8526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.8481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.8474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.8511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.8481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.8466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.8451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.8451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.8451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.8436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.8459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.8474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.8481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.8466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.8459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>0.8436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>0.8444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.8436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.8436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.8392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cutoff  train_acc  valid_acc\n",
       "0     0.30     0.9354     0.8459\n",
       "1     0.31     0.9373     0.8466\n",
       "2     0.32     0.9397     0.8474\n",
       "3     0.33     0.9416     0.8474\n",
       "4     0.34     0.9437     0.8496\n",
       "5     0.35     0.9473     0.8511\n",
       "6     0.36     0.9485     0.8511\n",
       "7     0.37     0.9497     0.8526\n",
       "8     0.38     0.9513     0.8526\n",
       "9     0.39     0.9526     0.8481\n",
       "10    0.40     0.9537     0.8474\n",
       "11    0.41     0.9547     0.8488\n",
       "12    0.42     0.9561     0.8488\n",
       "13    0.43     0.9582     0.8488\n",
       "14    0.44     0.9587     0.8511\n",
       "15    0.45     0.9585     0.8496\n",
       "16    0.46     0.9593     0.8481\n",
       "17    0.47     0.9619     0.8466\n",
       "18    0.48     0.9617     0.8451\n",
       "19    0.49     0.9623     0.8451\n",
       "20    0.50     0.9636     0.8451\n",
       "21    0.51     0.9636     0.8436\n",
       "22    0.52     0.9636     0.8459\n",
       "23    0.53     0.9647     0.8488\n",
       "24    0.54     0.9654     0.8496\n",
       "25    0.55     0.9647     0.8474\n",
       "26    0.56     0.9662     0.8481\n",
       "27    0.57     0.9663     0.8466\n",
       "28    0.58     0.9660     0.8459\n",
       "29    0.59     0.9654     0.8436\n",
       "30    0.60     0.9654     0.8444\n",
       "31    0.61     0.9641     0.8436\n",
       "32    0.62     0.9622     0.8436\n",
       "33    0.63     0.9604     0.8421\n",
       "34    0.64     0.9595     0.8392"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_table = pd.DataFrame({'cutoff': 1e-2*np.arange(30, 65, 1)})\n",
    "cutoff_table['train_acc'] = [np.round(accuracy_score(y_train, (train_pred > cutoff).astype(int)), 4)\n",
    "                             for cutoff in cutoff_table['cutoff']]\n",
    "cutoff_table['valid_acc'] = [np.round(accuracy_score(y_valid, (valid_pred > cutoff).astype(int)), 4)\n",
    "                             for cutoff in cutoff_table['cutoff']]\n",
    "cutoff_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607594936708861"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = (xgb_model.predict_proba(X_test)[:,1] > treshold).astype(int)\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X, y)\n",
    "y_REAL_test = (xgb_model.predict_proba(campaign_test)[:,1] > treshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521894548704201"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (xgb_model.predict_proba(X)[:,1] > treshold).astype(int)\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test_file_xgboost.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['Id', 'subscription'])\n",
    "for i in range(len(y_REAL_test)):\n",
    "    writer.writerow([i, y_REAL_test[i]])\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgboost = pd.read_csv('test_file_xgboost.csv')\n",
    "y_pred_boosting = pd.read_csv('test_file_boost.csv')\n",
    "y_pred_NN = pd.read_csv('test_file_neuralnets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('test_file_ensemble.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['Id', 'subscription'])\n",
    "for i in range(len(y_pred_xgboost)):\n",
    "    pred = int(np.round(np.mean([y_pred_boosting.loc[i,'subscription'],\n",
    "                                 y_pred_NN.loc[i,'subscription'],\n",
    "                                 y_pred_xgboost.loc[i,'subscription']])))\n",
    "    writer.writerow([i, pred])\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
